{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<!--\n",
    "---\n",
    "title: \"Linear Regression.\"\n",
    "author: \"Darya Vanichkina\"\n",
    "keypoints: \n",
    "- Regression is the prediction of the value of a continuous variable based on one or more other continuous or categorical variables.\n",
    "- Multiple types of regression can be implemented to fit the data\n",
    "\n",
    "questions:\n",
    "- How do we preprocess our data for modelling?\n",
    "- How do we fit a basic linear model using scikit-learn?\n",
    "\n",
    "objectives:\n",
    "- To use sklearn.preprocessing to preprocess our data\n",
    "- To fit and compare some basic linear models using one, two, or all of the variables in the dataset\n",
    "\n",
    "source: Rmd\n",
    "teaching: 30\n",
    "exercises: 15\n",
    "bibliography: references.bib\n",
    "---\n",
    "-->\n",
    "\n",
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# when delivering live coding, these libraries have already been loaded\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(font_scale = 1.5)\n",
    "#\n",
    "#\n",
    "#\n",
    "# do import these for the next sections to work:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pickle \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score,  mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions to help us one hot encode variables, group together infrequently occuring cases, and create a \"none of this feature\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# do live code the next code chunk\n",
    "def onehot_row_drop(df, column = 'column'):\n",
    "    df = pd.concat([df.drop(column, axis=1), pd.get_dummies(df[column], drop_first=True, prefix=column)],axis=1)\n",
    "    return(df)\n",
    "\n",
    "def group_infrequent(df, columnname,counts = 10):\n",
    "    df.loc[df[columnname].value_counts()[df[columnname]].values <= counts, columnname] = \"Other\"\n",
    "\n",
    "\n",
    "def none_of_this_feature(df, column = 'column'):\n",
    "    # adds a column to the dataframe with a value of 0 where there is none of this feature,\n",
    "    # and a 1 where it's actually there\n",
    "    df['No_' + column] = np.where(df[column]==0, 0, 1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to reload the data\n",
    "ameshousingClean = pd.read_csv('data/AmesHousingClean.csv')\n",
    "\n",
    "# But DO copy-paste the below code to proceed to the challenge\n",
    "# step 1\n",
    "ameshousingClean['Age'] = ameshousingClean['Year_Sold'].max() - ameshousingClean['Year_Built']\n",
    "ameshousingClean['Remodel_Age'] = ameshousingClean['Year_Sold'].max() - ameshousingClean['Year_Remod_Add']\n",
    "ameshousingClean['Misc_Feature_Present'] =  np.where(ameshousingClean['Misc_Feature']==\"None\", 0, 1)\n",
    "\n",
    "\n",
    "# step 2\n",
    "# group situations where there are less than 20 cases of something\n",
    "for i in ['Neighborhood', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Heating', 'MS_Zoning', 'Misc_Feature', 'Sale_Type']:\n",
    "    group_infrequent(df=ameshousingClean, columnname=i, counts=20)\n",
    "\n",
    "\n",
    "# Capture variables where some houses have \"none of this feature\" (i.e value of parameter = 0 aka zero-inflation)\n",
    "none_of_feature = ['Second_Flr_SF','Three_season_porch','BsmtFin_SF_2','Bsmt_Unf_SF','Enclosed_Porch','Low_Qual_Fin_SF',\n",
    "                   'Mas_Vnr_Area','Lot_Frontage','Open_Porch_SF','Screen_Porch','Pool_Area','Wood_Deck_SF', 'BsmtFin_SF_2', 'Second_Flr_SF']\n",
    "for i in none_of_feature:\n",
    "    ameshousingClean = none_of_this_feature(df = ameshousingClean, column=i)\n",
    "    \n",
    "# step 3\n",
    "categorical_variable_list = ['Alley', 'Bldg_Type', 'Condition_1', 'Electrical', 'Exter_Cond', 'Exter_Qual', \n",
    "                             'Foundation', 'Functional', 'House_Style', 'Kitchen_Qual', 'Land_Contour', \n",
    "                             'Land_Slope', 'Lot_Config', 'Lot_Shape', 'Central_Air', 'Bsmt_Cond', \n",
    "                             'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Bsmt_Qual', 'Fence', \n",
    "                             'Fireplace_Qu', 'Garage_Cond', 'Garage_Finish', 'Garage_Type', 'Heating_QC',  \n",
    "                              'MS_SubClass',  'Overall_Cond', 'Overall_Qual', \n",
    "                             'Paved_Drive', 'Roof_Style', 'Year_Sold', 'Neighborhood', 'Roof_Matl', 'Exterior_2nd',\n",
    "                            'Exterior_1st', 'Heating', 'MS_Zoning', 'Misc_Feature', 'Street', 'Mas_Vnr_Type', 'Utilities',\"Condition_2\", \"Pool_QC\", \"Garage_Qual\", 'Sale_Type', 'Sale_Condition']\n",
    "\n",
    "# step 4\n",
    "# one hot encode the other categoricals\n",
    "for i in categorical_variable_list:\n",
    "    ameshousingClean = onehot_row_drop(df = ameshousingClean, column=i)\n",
    "\n",
    "# step 5\n",
    "# drop double no basement: (ranges from 80 to 83 in dataset, going with 80)\n",
    "ameshousingClean = ameshousingClean.drop('Bsmt_Exposure_No_Basement', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('BsmtFin_Type_2_No_Basement', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Bsmt_Qual_No_Basement', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Garage_Finish_No_Garage', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Garage_Type_No_Garage', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Garage_Qual_No_Garage', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Year_Built', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Year_Remod_Add', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Challenge 1\n",
    ">\n",
    "> Look at the code above. Can you explain why each of these transformations is being carried out? \n",
    "> See if you can figure out, in your groups, what each of the steps is doing.\n",
    "> \n",
    "> {: .source}\n",
    ">\n",
    "> > ## Solution\n",
    "> > \n",
    "> > {: .output}\n",
    "> {: .solution}\n",
    "{: .challenge}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Add a column to the dataset to split the Sale Price by percentile into 10 bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "ameshousingClean['Sale_Price_quartile'] =  pd.qcut(ameshousingClean['Sale_Price'], 10, labels=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Now we can use scikit-learn's train-test split to split the data into a training and testing subset, stratifying it by the percentile bin of the Sale_Price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "index_train, index_test  = train_test_split(np.array(ameshousingClean.index), train_size=0.7, test_size = 0.3, \n",
    "                                            stratify = np.array(ameshousingClean['Sale_Price_quartile']), random_state=42)\n",
    "ameshousingClean = ameshousingClean.drop('Sale_Price_quartile', axis = 1)\n",
    "\n",
    "# Create variables for the training and test sets \n",
    "ames_train = ameshousingClean.loc[index_train,:].copy()\n",
    "ames_test =  ameshousingClean.loc[index_test,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2051, 287)\n",
      "(879, 287)\n"
     ]
    }
   ],
   "source": [
    "# What are their dimensions?\n",
    "print(ames_train.shape)\n",
    "print(ames_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Get a list of predictor names and make numpy matrices of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "predictors = list(ameshousingClean.columns)\n",
    "predictors.remove('Sale_Price')\n",
    "\n",
    "# this is extra, to help keep  the train/test consistent between different page renders\n",
    "# in jekyll. Not necessary for teaching\n",
    "pickle.dump(predictors, open('models/predictors.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Create training and test response vectors\n",
    "ames_train_y = np.log10(ames_train['Sale_Price'])\n",
    "ames_test_y = np.log10(ames_test['Sale_Price'])\n",
    "\n",
    "# Write training and test design matrices\n",
    "ames_train_X = ames_train[predictors].copy()\n",
    "ames_test_X = ames_test[predictors].copy()\n",
    "\n",
    "\n",
    "# save them to files as well (this is an extra step that's not necessary in class, but useful for our jupyter notebook class notes)\n",
    "pickle.dump(ames_train_y, open('models/ames_train_y.pickle', 'wb'))\n",
    "pickle.dump(ames_test_y, open('models/ames_test_y.pickle', 'wb'))\n",
    "pickle.dump(ames_train_X, open('models/ames_train_X.pickle', 'wb'))\n",
    "pickle.dump(ames_test_X, open('models/ames_test_X.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ames_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit OLS models with different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit an Ordinary Least Squares Regression using all variables\n",
    "ames_ols_all = LinearRegression()\n",
    "ames_ols_all.fit(ames_train_X, ames_train_y)\n",
    "\n",
    "\n",
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area\n",
    "ames_ols_GrLivArea = LinearRegression()\n",
    "ames_ols_GrLivArea.fit(ames_train_X['Gr_Liv_Area'].values.reshape(-1, 1), ames_train_y)\n",
    "\n",
    "## \n",
    "ames_ols_Second_Flr_SF = LinearRegression()\n",
    "ames_ols_Second_Flr_SF.fit(ames_train_X['Second_Flr_SF'].values.reshape(-1, 1), ames_train_y)\n",
    "\n",
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area and Second_Flr_SF\n",
    "ames_ols_GrLivArea_Second_Flr_SF = LinearRegression()\n",
    "ames_ols_GrLivArea_Second_Flr_SF.fit(ames_train_X[['Gr_Liv_Area','Second_Flr_SF']], ames_train_y)\n",
    "\n",
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area and Age\n",
    "ames_ols_GrLivArea_Age = LinearRegression()\n",
    "ames_ols_GrLivArea_Age.fit(ames_train_X[['Gr_Liv_Area','Age']], ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Assess model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess model fit on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>18810.886</td>\n",
       "      <td>0.946</td>\n",
       "      <td>11761.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Gr_Liv_Area, Age]</th>\n",
       "      <td>50897.025</td>\n",
       "      <td>0.603</td>\n",
       "      <td>29818.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <td>64884.161</td>\n",
       "      <td>0.355</td>\n",
       "      <td>40056.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <td>78956.645</td>\n",
       "      <td>0.046</td>\n",
       "      <td>53158.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Gr_Liv_Area, Second_Flr_SF]</th>\n",
       "      <td>79609.931</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38615.494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   RMSE     R2        MAE\n",
       ":                             18810.886  0.946  11761.208\n",
       "[Gr_Liv_Area, Age]            50897.025  0.603  29818.203\n",
       "Gr_Liv_Area                   64884.161  0.355  40056.146\n",
       "Second_Flr_SF                 78956.645  0.046  53158.416\n",
       "[Gr_Liv_Area, Second_Flr_SF]  79609.931  0.030  38615.494"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Paste the function below, then go slowly through how it is built up\n",
    "def assess_fit_vars(listOfMethods, variables, datasetX, datasetY):\n",
    "    columns= ['RMSE', 'R2', 'MAE']\n",
    "    rows=variables\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "    for i, method in enumerate(methods):\n",
    "        if variables[i] != \":\":\n",
    "            tmp_dataset_X = datasetX[variables[i]]\n",
    "            if type(variables[i]) == str: #only one column - so need to reshape\n",
    "                tmp_dataset_X = datasetX[variables[i]].values.reshape(-1, 1)\n",
    "        else:\n",
    "            tmp_dataset_X=datasetX\n",
    "        # while we build the model and predict on the log10Transformed sale price, we display the error in dollars\n",
    "        # as that makes more sense\n",
    "        y_pred=10**(method.predict(tmp_dataset_X))\n",
    "        results.iloc[i,0] = np.sqrt(mean_squared_error(10**(datasetY), y_pred))\n",
    "        results.iloc[i,1] = r2_score(10**(datasetY), y_pred)\n",
    "        results.iloc[i,2] = mean_absolute_error(10**(datasetY), y_pred)\n",
    "    return(results.round(3))\n",
    "\n",
    "methods =[ames_ols_all,  ames_ols_GrLivArea, ames_ols_Second_Flr_SF, ames_ols_GrLivArea_Age, ames_ols_GrLivArea_Second_Flr_SF]\n",
    "\n",
    "variables =[\":\", 'Gr_Liv_Area','Second_Flr_SF',['Gr_Liv_Area', 'Age'], ['Gr_Liv_Area', 'Second_Flr_SF']]\n",
    "\n",
    "compare_train = assess_fit_vars(listOfMethods = methods,variables=variables, datasetX = ames_train_X, datasetY = ames_train_y)\n",
    "compare_train.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with peformance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GrLivArea_Age</th>\n",
       "      <td>61910.789</td>\n",
       "      <td>0.364</td>\n",
       "      <td>29520.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>64792.914</td>\n",
       "      <td>0.303</td>\n",
       "      <td>16436.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <td>75173.157</td>\n",
       "      <td>0.062</td>\n",
       "      <td>51792.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>76804.438</td>\n",
       "      <td>0.021</td>\n",
       "      <td>39238.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea Second_Flr_SF</th>\n",
       "      <td>106083.367</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>38218.077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               RMSE     R2        MAE\n",
       "GrLivArea_Age             61910.789  0.364  29520.827\n",
       "All                       64792.914  0.303  16436.269\n",
       "Second_Flr_SF             75173.157  0.062  51792.088\n",
       "GrLivArea                 76804.438  0.021  39238.397\n",
       "GrLivArea Second_Flr_SF  106083.367 -0.868  38218.077"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on the test! set\n",
    "compare = assess_fit_vars(listOfMethods = methods,variables=variables, datasetX = ames_test_X, datasetY = ames_test_y)\n",
    "compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "32\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# lets explore the coefficients\n",
    "print(ameshousingClean.columns.get_loc('Gr_Liv_Area'))\n",
    "print(ameshousingClean.columns.get_loc('Age'))\n",
    "print(ameshousingClean.columns.get_loc('Second_Flr_SF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Challenge 2\n",
    ">\n",
    "> 1. Explore the coefficients for Gr_Liv_Area, Second_Flr_SF,  Gr_Liv_Area + Second_Flr_SF, \n",
    "> Gr_Liv_Area + Age, and the coefficients for these parameters for a model that \n",
    "> incorporates all of them. What do you observe? Are the coefficients for each parameter consistent among all the models?\n",
    ">\n",
    "> 2. Which model performs the best? Why? \n",
    ">\n",
    "> 3. Does the same model perform best for the training and test data? Why?\n",
    ">\n",
    ">\n",
    ">\n",
    "> {: .source}\n",
    ">\n",
    "> > ## Solution\n",
    "> > \n",
    "> > This is a discussion challenge. Answers will be discussed as a group. \n",
    "> > To get the coefficients for each model, use the `ames_ols_GrLivArea.coef_` method.\n",
    "> > ~~~\n",
    "> > ames_ols_GrLivArea.coef_\n",
    "> > ames_ols_Second_Flr_SF.coef_\n",
    "> > ames_ols_GrLivArea_Age.coef_\n",
    "> > ames_ols_GrLivArea_Second_Flr_SF.coef_\n",
    "> > ~~~\n",
    "> > \n",
    "> > {: .output}\n",
    "> {: .solution}\n",
    "{: .challenge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below is only necessary to build the web pages; do not use for class\n",
    "# save OLS model to pickle\n",
    "pickle.dump(ames_ols_all, open('models/ames_ols_all.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
