---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 11-RidgeLassoElasticNet.md in _episodes_rmd/
title: "Regularised Regression. Principle components Regression. Partial Least Squares Regression."
author: "Darya Vanichkina"
keypoints:
- Regularisation helps us improve the performance of regression
- 
objectives:
- someobjective
questions:
- How do we prevent all variables from being incorporated into a regression model?
source: Rmd
start: 0
teaching: 30
exercises: 0
---




```r
library(tidyverse)
```

```
## ── Attaching packages ────────────────────────────────── tidyverse 1.2.1 ──
```

```
## ✔ ggplot2 3.1.0       ✔ purrr   0.3.1  
## ✔ tibble  2.0.1       ✔ dplyr   0.8.0.1
## ✔ tidyr   0.8.3       ✔ stringr 1.4.0  
## ✔ readr   1.3.1       ✔ forcats 0.4.0
```

```
## Warning: package 'tibble' was built under R version 3.5.2
```

```
## Warning: package 'tidyr' was built under R version 3.5.2
```

```
## Warning: package 'purrr' was built under R version 3.5.2
```

```
## Warning: package 'dplyr' was built under R version 3.5.2
```

```
## Warning: package 'stringr' was built under R version 3.5.2
```

```
## Warning: package 'forcats' was built under R version 3.5.2
```

```
## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
```

```r
library(caret)
```

```
## Loading required package: lattice
```

```
## 
## Attaching package: 'caret'
```

```
## The following object is masked from 'package:purrr':
## 
##     lift
```

```r
library(tidymodels)
```

```
## ── Attaching packages ───────────────────────────────── tidymodels 0.0.2 ──
```

```
## ✔ broom     0.5.1     ✔ recipes   0.1.4
## ✔ dials     0.0.2     ✔ rsample   0.0.4
## ✔ infer     0.4.0     ✔ yardstick 0.0.3
## ✔ parsnip   0.0.1
```

```
## Warning: package 'rsample' was built under R version 3.5.2
```

```
## Warning: package 'yardstick' was built under R version 3.5.2
```

```
## ── Conflicts ──────────────────────────────────── tidymodels_conflicts() ──
## ✖ scales::discard()      masks purrr::discard()
## ✖ dplyr::filter()        masks stats::filter()
## ✖ recipes::fixed()       masks stringr::fixed()
## ✖ dplyr::lag()           masks stats::lag()
## ✖ caret::lift()          masks purrr::lift()
## ✖ yardstick::precision() masks caret::precision()
## ✖ yardstick::recall()    masks caret::recall()
## ✖ yardstick::spec()      masks readr::spec()
## ✖ recipes::step()        masks stats::step()
```

```r
library(AmesHousing)
```


```
## Error in strata %in% vars: object 'ameshousingFilt' not found
```

```
## Error in analysis(x): object 'ames_split' not found
```

```
## Error in assessment(x): object 'ames_split' not found
```


## Regularised Regression. 




## Principle components Regression. 


```r
set.seed(42)
cv_pcr <- train(
  Sale_Price ~ ., 
  data = ameshousingFiltTrain_engineered,
  trControl = cv,
  method = "pcr", 
  tuneGrid = expand.grid(ncomp = seq(180, 219, length.out =  10)), 
  metric = "RMSE"
  )
```

```
## Error in eval(expr, p): object 'ameshousingFiltTrain_engineered' not found
```

```r
# 189

cv_pcr$results %>% filter(ncomp == cv_pcr$bestTune$ncomp)
```

```
## Error in eval(lhs, parent, parent): object 'cv_pcr' not found
```

```r
plot(cv_pcr)
```

```
## Error in plot(cv_pcr): object 'cv_pcr' not found
```




## Partial Least Squares Regression.








```r
# 1. stratified sampling with the rsample package
set.seed(123)
split  <- initial_split(ames, prop = 0.7, strata = "Sale_Price")
```

```
## Error in strata %in% vars: object 'ames' not found
```

```r
ames_train  <- training(split)
```

```
## Error: `x` should be an `rsplit` object
```

```r
ames_test   <- testing(split)
```

```
## Error: `x` should be an `rsplit` object
```

```r
# 2. create a resampling method
cv <- trainControl(
  method = "repeatedcv", 
  number = 10, 
  repeats = 5
  )
# 3. create a hyperparameter grid search
hyper_grid <- expand.grid(k = seq(2, 26, by = 2))
# 4. execute grid search with knn model
#    use RMSE as preferred metric
knn_fit <- train(
  Sale_Price ~ ., 
  data = ames_train, 
  method = "knn", 
  trControl = cv, 
  tuneGrid = hyper_grid,
  metric = "RMSE"
  )
```

```
## Error in eval(expr, p): object 'ames_train' not found
```

```r
# 5. evaluate results
# print model results
knn_fit
```

```
## Error in eval(expr, envir, enclos): object 'knn_fit' not found
```

```r
## k-Nearest Neighbors 
## 
## 2054 samples
##   80 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 1848, 1850, 1848, 1848, 1848, 1848, ... 
## Resampling results across tuning parameters:
## 
##   k   RMSE      Rsquared   MAE     
##    2  46100.84  0.6618945  30205.06
```

