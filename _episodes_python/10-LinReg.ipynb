{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "---\n",
    "title: \"Linear Regression.\"\n",
    "author: \"Darya Vanichkina\"\n",
    "exercises: 0\n",
    "keypoints: \n",
    "- Regression is the prediction of the value of a continuous variable based on one or more other continuous or categorical variables.\n",
    "- Multiple types of regression can be implemented to fit the data\n",
    "source: Rmd\n",
    "start: 0\n",
    "teaching: 30\n",
    "bibliography: references.bib\n",
    "---\n",
    "-->\n",
    "\n",
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score,  mean_absolute_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_row_drop(df, column = 'column'):\n",
    "    df = pd.concat([df.drop(column, axis=1), pd.get_dummies(df[column], drop_first=True, prefix=column)],axis=1)\n",
    "    return(df)\n",
    "\n",
    "def group_infrequent(df, columnname,counts = 10):\n",
    "    df.loc[df[columnname].value_counts()[df[columnname]].values <= counts, columnname] = \"Other\"\n",
    "\n",
    "\n",
    "def none_of_this_feature(df, column = 'column'):\n",
    "    # adds a column to the dataframe wtih a value of 0 where there is none of this feature,\n",
    "    # and a 1 where it's actually there\n",
    "    df['No_' + column] = np.where(df[column]==0, 0, 1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "ameshousingClean = pd.read_csv('data/AmesHousingClean.csv')\n",
    "\n",
    "ameshousingClean['Age'] = ameshousingClean['Year_Sold'].max() - ameshousingClean['Year_Built']\n",
    "ameshousingClean['Remodel_Age'] = ameshousingClean['Year_Sold'].max() - ameshousingClean['Year_Remod_Add']\n",
    "ameshousingClean['Misc_Feature_Present'] =  np.where(ameshousingClean['Misc_Feature']==\"None\", 0, 1)\n",
    "\n",
    "\n",
    "# group situations where there are less than 20 cases of something\n",
    "for i in ['Neighborhood', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Heating', 'MS_Zoning', 'Misc_Feature', 'Sale_Type']:\n",
    "    group_infrequent(df=ameshousingClean, columnname=i, counts=20)\n",
    "\n",
    "\n",
    "# Capture variables where some houses have \"none of this feature\" (i.e value of parameter = 0 aka zero-inflation)\n",
    "none_of_feature = ['Second_Flr_SF','Three_season_porch','BsmtFin_SF_2','Bsmt_Unf_SF','Enclosed_Porch','Low_Qual_Fin_SF',\n",
    "                   'Mas_Vnr_Area','Lot_Frontage','Open_Porch_SF','Screen_Porch','Pool_Area','Wood_Deck_SF', 'BsmtFin_SF_2', 'Second_Flr_SF']\n",
    "for i in none_of_feature:\n",
    "    ameshousingClean = none_of_this_feature(df = ameshousingClean, column=i)\n",
    "    \n",
    "    \n",
    "\n",
    "categorical_variable_list = ['Alley', 'Bldg_Type', 'Condition_1', 'Electrical', 'Exter_Cond', 'Exter_Qual', \n",
    "                             'Foundation', 'Functional', 'House_Style', 'Kitchen_Qual', 'Land_Contour', \n",
    "                             'Land_Slope', 'Lot_Config', 'Lot_Shape', 'Central_Air', 'Bsmt_Cond', \n",
    "                             'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Bsmt_Qual', 'Fence', \n",
    "                             'Fireplace_Qu', 'Garage_Cond', 'Garage_Finish', 'Garage_Type', 'Heating_QC',  \n",
    "                              'MS_SubClass',  'Overall_Cond', 'Overall_Qual', \n",
    "                             'Paved_Drive', 'Roof_Style', 'Year_Sold', 'Neighborhood', 'Roof_Matl', 'Exterior_2nd',\n",
    "                            'Exterior_1st', 'Heating', 'MS_Zoning', 'Misc_Feature', 'Street', 'Mas_Vnr_Type', 'Utilities',\"Condition_2\", \"Pool_QC\", \"Garage_Qual\", 'Sale_Type', 'Sale_Condition']\n",
    "\n",
    "# one hot encode the other categoricals\n",
    "for i in categorical_variable_list:\n",
    "    ameshousingClean = onehot_row_drop(df = ameshousingClean, column=i)\n",
    "\n",
    "# drop double no basement: (ranges from 80 to 83 in dataset, going with 80)\n",
    "ameshousingClean = ameshousingClean.drop('Bsmt_Exposure_No_Basement', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('BsmtFin_Type_2_No_Basement', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Bsmt_Qual_No_Basement', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Garage_Finish_No_Garage', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Garage_Type_No_Garage', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Garage_Qual_No_Garage', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Year_Built', axis=1)\n",
    "ameshousingClean = ameshousingClean.drop('Year_Remod_Add', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column to the dataset to split the Sale Price by percentile into 10 bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "ameshousingClean['Sale_Price_quartile'] =  pd.qcut(ameshousingClean['Sale_Price'], 10, labels=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use scikit-learn's train-test split to split the data into a training and testing subset, stratifying it by the percentile bin of the Sale_Price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train, index_test  = train_test_split(np.array(ameshousingClean.index), train_size=0.7, test_size = 0.3, \n",
    "                                            stratify = np.array(ameshousingClean['Sale_Price_quartile']), random_state=42)\n",
    "ameshousingClean = ameshousingClean.drop('Sale_Price_quartile', axis = 1)\n",
    "\n",
    "# Create variables for the training and test sets \n",
    "ames_train = ameshousingClean.loc[index_train,:].copy()\n",
    "ames_test =  ameshousingClean.loc[index_test,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2051, 288)\n",
      "(879, 288)\n"
     ]
    }
   ],
   "source": [
    "# What are their dimensions?\n",
    "print(ames_train.shape)\n",
    "print(ames_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of predictor names and make numpy matrices of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(ameshousingClean.columns)\n",
    "predictors.remove('Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test response vectors\n",
    "ames_train_y = np.log(ames_train['Sale_Price'])\n",
    "ames_test_y = np.log(ames_test['Sale_Price'])\n",
    "\n",
    "# Write training and test design matrices\n",
    "ames_train_X = ames_train[predictors].copy()\n",
    "ames_test_X = ames_test[predictors].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an Ordinary Least Squares Regression using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_ols_all = LinearRegression()\n",
    "ames_ols_all.fit(ames_train_X, ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_ols_GrLivArea = LinearRegression()\n",
    "ames_ols_GrLivArea.fit(ames_train_X['Gr_Liv_Area'].values.reshape(-1, 1), ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area and Second_Flr_SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_ols_GrLivArea_Second_Flr_SF = LinearRegression()\n",
    "ames_ols_GrLivArea_Second_Flr_SF.fit(ames_train_X[['Gr_Liv_Area','Second_Flr_SF']], ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area and Second_Flr_SF, with an interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create interaction term (not polynomial features)\n",
    "interaction = PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)\n",
    "X_inter = interaction.fit_transform(ames_train_X[['Gr_Liv_Area','Second_Flr_SF']])\n",
    "ames_ols_GrLivArea_Second_Flr_SF_interaction = LinearRegression()\n",
    "ames_ols_GrLivArea_Second_Flr_SF_interaction.fit(X_inter, ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an Ordinary Least Squares Regression using Gr_Liv_Area and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_ols_GrLivArea_Second_Flr_SF = LinearRegression()\n",
    "ames_ols_GrLivArea_Second_Flr_SF.fit(ames_train_X[['Gr_Liv_Area','Age']], ames_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Test RMSE', 'Test R2', 'Test MAE']\n",
    "rows=['All', 'GrLivArea', 'GrLivArea_Age', 'GrLivArea Second_Flr_SF', 'GrLivArea Second_Flr_SF w/interaction']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "\n",
    "# this will work for other stuff but not the above as different variable selections\n",
    "def assess_fit(listOfMethods, testX, testY):\n",
    "    for i, method in enumerate(methods):\n",
    "        y_pred=np.exp(method.predict(testX))   \n",
    "        results.iloc[i,0] = np.sqrt(mean_squared_error(np.exp(testY), y_pred))\n",
    "        results.iloc[i,1] = r2_score(np.exp(testY), y_pred)\n",
    "        results.iloc[i,2] = mean_absolute_error(np.exp(testY), y_pred)\n",
    "    return(results.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (879,287) and (1,) not aligned: 287 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-c3a9c3bb282b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mames_ols_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mames_ols_GrLivArea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mames_ols_GrLivArea_Second_Flr_SF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mames_ols_GrLivArea_Second_Flr_SF_interaction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfMethods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mames_test_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mames_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-262-bba18c029d55>\u001b[0m in \u001b[0;36massess_fit\u001b[0;34m(listOfMethods, testX, testY)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massess_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfMethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 198\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (879,287) and (1,) not aligned: 287 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "methods =[ames_ols_all, ames_ols_GrLivArea, ames_ols_GrLivArea_Second_Flr_SF, ames_ols_GrLivArea_Second_Flr_SF_interaction]\n",
    "compare = assess_fit(listOfMethods = methods, testX = ames_test_X, testY = ames_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
