{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression (...continued)\n",
    "\n",
    "## further methods & comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score,  mean_absolute_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Set up plotting options for seaborn and matplotlib\n",
    "sns.set_context('notebook') \n",
    "sns.set_style('ticks') \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load from previous lessons\n",
    "cached_files = ['models/ames_train_y.pickle','models/ames_test_y.pickle',\n",
    "                'models/ames_train_X.pickle','models/ames_test_X.pickle',\n",
    "                'models/predictors.pickle','models/ames_ols_all.pickle',\n",
    "                'models/ames_ridge.pickle','models/ames_lasso.pickle', \n",
    "                'models/ames_enet.pickle']\n",
    "\n",
    "for file in cached_files:\n",
    "    with open(file, 'rb') as f:\n",
    "        objectname = file.replace('models/', '').replace('.pickle', '')\n",
    "        exec(objectname + \" = pickle.load(f)\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "In random forest, each tree in the ensemble is built from a bootstrap sample from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is the best split among a random subset of the features. The scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning grid will be defined to optimise the following RF parameters:\n",
    "# n_estimators\n",
    "# criterion\n",
    "nEstimators_arr = np.arange(50,120,50)\n",
    "criteria_arr = ['mse','mae']\n",
    "parametersGrid = {\"n_estimators\": nEstimators_arr,\n",
    "                  \"criterion\": criteria_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ames_RF = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', RandomForestRegressor(n_estimators=100))\n",
    "    #('estimator', GridSearchCV(RandomForestRegressor(), parametersGrid, scoring='r2', cv=10))\n",
    "])\n",
    "\n",
    "ames_RF.fit(ames_train_X, ames_train_y)\n",
    "\n",
    "## Toggle comment below to build model\n",
    "# ames_RF.fit(ames_train_X, ames_train_y)\n",
    "pickle.dump(ames_RF, open('models/ames_rforest.pickle', 'wb'))\n",
    "#with open('models/ames_rforest.pickle', 'rb') as f:\n",
    "#    ames_RF = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ames_RF)\n",
    "#best_params_RF = ames_RF.named_steps.estimator.best_estimator_\n",
    "#print(best_params_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Challenge 1\n",
    ">\n",
    "> 1. Look at the coefficients for the model above. What was the balance between L1 (Lasso) and L2 (Ridge) regression?\n",
    "> 2. What value of alpha was found to be optimal? Was this value expected based on the results we got when we ran Lasso and Ridge independently?\n",
    "> \n",
    "> {: .source}\n",
    ">\n",
    "> > ## Solution\n",
    "> > \n",
    "> > 2. See [this answer](https://stackoverflow.com/questions/47365978/scikit-learn-elastic-net-approaching-ridge) for an explanation why the \n",
    "> >  two values of alpha were not the same.\n",
    "> > {: .output}\n",
    "> {: .solution}\n",
    "{: .challenge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_coefficients(model, labels):\n",
    "    #coef = model.coef_\n",
    "    coef = model.feature_importances_\n",
    "\n",
    "    table = pd.Series(coef.ravel(), index = labels).sort_values(ascending=True, inplace=False)\n",
    "    \n",
    "    reference = pd.Series(np.abs(coef.ravel()), index = labels).sort_values(ascending=False, inplace=False)\n",
    "    reference = reference.iloc[:20]\n",
    "    table = table[reference.index]\n",
    "    table = table.sort_values(ascending=True, inplace=False)\n",
    "\n",
    "    fig, ax = fig, ax = plt.subplots()\n",
    "    table.T.plot(kind='barh', edgecolor='black', width=0.7, linewidth=.8, alpha=0.9, ax=ax)\n",
    "    ax.tick_params(axis=u'y', length=0) \n",
    "    #ax.set_title('Estimated coefficients (twenty largest in absolute value)', fontsize=14)\n",
    "    ax.set_title('Feature Importances (twenty largest in absolute value)', fontsize=14)\n",
    "    sns.despine()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_coefficients(ames_RF._final_estimator, predictors)# the final_estimator attribute refers to the pipeline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbours Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "\n",
    "linreg = LinearRegression()\n",
    "pca = PCA()\n",
    "\n",
    "pipe = Pipeline(steps=[('pca', pca), ('linreg', linreg)])\n",
    "param_grid = {'pca__n_components': np.arange(1,len(ames_train_X.columns), 40)}\n",
    "ames_pcr = GridSearchCV(pipe, param_grid, iid=False, cv=5,\n",
    "                      return_train_score=False)\n",
    "\n",
    "ames_pcr.fit(ames_train_X, ames_train_y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % ames_pcr.best_score_)\n",
    "print(ames_pcr.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What was the RMSE on the training data?\n",
    "columns=['Train RMSE']\n",
    "rows=['OLS','Ridge', 'Lasso', 'ENet', 'Random Forest']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[ames_ols_all, ames_ridge, ames_lasso, ames_enet, ames_RF]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    y_pred=method.predict(ames_train_X)\n",
    "    results.iloc[i,0] = np.sqrt(mean_squared_error(10**ames_train_y, 10**y_pred))\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare with the test data!\n",
    "columns=['Test RMSE']\n",
    "rows=['OLS','Ridge', 'Lasso', 'ENet', 'Random Forest']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[ames_ols_all,  ames_ridge, ames_lasso, ames_enet, ames_RF]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    y_pred=method.predict(ames_test_X)\n",
    "    results.iloc[i,0] = np.sqrt(mean_squared_error(10**ames_test_y, 10**y_pred))\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
