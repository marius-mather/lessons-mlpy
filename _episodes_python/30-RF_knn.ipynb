{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression (...continued)\n",
    "\n",
    "## further methods & comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score,  mean_absolute_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Set up plotting options for seaborn and matplotlib\n",
    "sns.set_context('notebook') \n",
    "sns.set_style('ticks') \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load from previous lessons\n",
    "cached_files = ['models/ames_train_y.pickle','models/ames_test_y.pickle',\n",
    "                'models/ames_train_X.pickle','models/ames_test_X.pickle',\n",
    "                'models/predictors.pickle','models/ames_ols_all.pickle',\n",
    "                'models/ames_ridge.pickle','models/ames_lasso.pickle', \n",
    "                'models/ames_enet.pickle']\n",
    "\n",
    "for file in cached_files:\n",
    "    with open(file, 'rb') as f:\n",
    "        objectname = file.replace('models/', '').replace('.pickle', '')\n",
    "        exec(objectname + \" = pickle.load(f)\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "In random forest, each tree in the ensemble is built from a bootstrap sample from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is the best split among a random subset of the features. The scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning grid will be defined to optimise the following RF parameters:\n",
    "# n_estimators\n",
    "# min_samples_leaf\n",
    "\n",
    "nEstimators_arr = [50] #np.arange(50,120,30)\n",
    "minSampLeaf_arr = [3] #np.arange(2,7,2)\n",
    "param_grid_RF = {\"n_estimators\": nEstimators_arr,\n",
    "                 \"min_samples_leaf\": minSampLeaf_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "ames_RF = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', GridSearchCV(RandomForestRegressor(), param_grid_RF, scoring='r2', cv=10))\n",
    "])\n",
    "\n",
    "## Toggle comment below to build model\n",
    "ames_RF.fit(ames_train_X, ames_train_y)\n",
    "pickle.dump(ames_RF, open('models/ames_rforest.pickle', 'wb'))\n",
    "#with open('models/ames_rforest.pickle', 'rb') as f:\n",
    "#    ames_RF = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_RF = ames_RF.named_steps.estimator.best_estimator_\n",
    "print(best_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Challenge 1\n",
    ">\n",
    "> 1. Look at the coefficients for the model above. How many trees are worth combining?\n",
    "> 2. Which minimum leaf size is best?\n",
    "> \n",
    "> {: .source}\n",
    ">\n",
    "> > ## Solution\n",
    "> > \n",
    "> > 1.\n",
    "> > 2. \n",
    "> > {: .output}\n",
    "> {: .solution}\n",
    "{: .challenge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_coefficients(model, labels):\n",
    "    importance = model.feature_importances_\n",
    "\n",
    "    table = pd.Series(importance.ravel(), index = labels).sort_values(ascending=True, inplace=False)\n",
    "    \n",
    "    reference = pd.Series(np.abs(importance.ravel()), index = labels).sort_values(ascending=False, inplace=False)\n",
    "    reference = reference.iloc[:20]\n",
    "    table = table[reference.index]\n",
    "    table = table.sort_values(ascending=True, inplace=False)\n",
    "\n",
    "    fig, ax = fig, ax = plt.subplots()\n",
    "    table.T.plot(kind='barh', edgecolor='black', width=0.7, linewidth=.8, alpha=0.9, ax=ax)\n",
    "    ax.tick_params(axis=u'y', length=0) \n",
    "    ax.set_title('Feature Importances (twenty largest in absolute value)', fontsize=14)\n",
    "    sns.despine()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_coefficients(best_RF, predictors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbours Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning grid will be defined to optimise the following kNN parameters:\n",
    "# n_neighbors\n",
    "# weights\n",
    "nNeighbors_arr = [10] #np.arange(4,20,2)\n",
    "weights_arr = ['uniform'] #['uniform','distance']\n",
    "param_grid_kNN = {\"n_neighbors\": nNeighbors_arr,\n",
    "                  \"weights\": weights_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "ames_kNN = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', GridSearchCV(KNeighborsRegressor(), param_grid_kNN, scoring='r2', cv=10))\n",
    "])\n",
    "\n",
    "\n",
    "## Toggle comment below to build model\n",
    "ames_kNN.fit(ames_train_X, ames_train_y)\n",
    "pickle.dump(ames_kNN, open('models/ames_knn.pickle', 'wb'))\n",
    "#with open('models/ames_knn.pickle', 'rb') as f:\n",
    "#    ames_kNN = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_kNN = ames_kNN.named_steps.estimator.best_estimator_\n",
    "print(best_kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What was the RMSE on the training data?\n",
    "columns=['Train RMSE']\n",
    "rows=['OLS','Ridge', 'Lasso', 'ENet', 'Random Forest', 'k Nearest Neighbours']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[ames_ols_all, ames_ridge, ames_lasso, ames_enet, ames_RF, ames_kNN]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    y_pred=method.predict(ames_train_X)\n",
    "    results.iloc[i,0] = np.sqrt(mean_squared_error(10**ames_train_y, 10**y_pred))\n",
    "\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare with the test data!\n",
    "columns=['Test RMSE']\n",
    "rows=['OLS','Ridge', 'Lasso', 'ENet', 'Random Forest', 'k Nearest Neighbours']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[ames_ols_all,  ames_ridge, ames_lasso, ames_enet, ames_RF, ames_kNN]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    y_pred=method.predict(ames_test_X)\n",
    "    results.iloc[i,0] = np.sqrt(mean_squared_error(10**ames_test_y, 10**y_pred))\n",
    "\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
